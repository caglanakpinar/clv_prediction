models:
  next_purchase:
    params:
      activation: relu
      batch_size: 1
      epochs: 50
      l1: 0.01
      l2: 0.01
      lag: 4
      lahead: 4
      lr: 0.001
      split_ratio: 0.8
      tsteps: 1
      units: 128
    hyper_params:
      batch_sizes:
        - 4
        - 8
        - 16
        - 32
        - 64
        - 128
        - 1024
        - 2048
      activation: relu_tanh
      epochs:
        - 4
        - 8
        - 16
        - 32
        - 64
        - 128
      split_ratio: 0.8
      filters:
        - 1
        - 2
      l1:
        - 0.01
        - 0.02
        - 0.03
        - 0.04
        - 0.05
        - 0.001
        - 0.001
        - 0.001
        - 0.001
        - 0.001
        - 0.0001
        - 0.0002
        - 0.0003
        - 0.0004
        - 0.0005
        - 0.1
        - 0.2
      l2:
        - 0.01
        - 0.02
        - 0.03
        - 0.04
        - 0.05
        - 0.001
        - 0.001
        - 0.001
        - 0.001
        - 0.001
        - 0.0001
        - 0.0002
        - 0.0003
        - 0.0004
        - 0.0005
        - 0.1
        - 0.2
      lr:
        - 0.01
        - 0.02
        - 0.03
        - 0.04
        - 0.05
        - 0.001
        - 0.001
        - 0.001
        - 0.001
        - 0.001
        - 0.0001
        - 0.0002
        - 0.0003
        - 0.0004
        - 0.0005
        - 0.1
        - 0.2
      kernel_size:
        - 2
        - 4
      max_pooling_unit:
        - 1
        - 2
        - 3
        - 4
      lstm_units:
        - 4
        - 8
        - 16
        - 32
        - 64
        - 128
      units:
        - 4
        - 8
        - 16
        - 32
        - 64
        - 128
      loss:
        - mae
        - mse
      drop_out_ratio: 0.1*0.5
  purchase_amount:
    params:
      feature_count: 5
      activation: relu
      batch_size: 32
      epochs: 40
      l1: 0.0001
      l2: 0.0001
      lr: 0.001
      split_ratio: 0.8
      filters: 2
      kernel_size: 4
      max_pooling_unit: 2
      lstm_units: 32
      units: 8
      loss: mae
      drop_out_ratio: 0.1
      num_layers: 1
    hyper_params:
      activation: relu_tanh_sigmoid_softmax
      epochs:
        - 4
        - 8
        - 16
        - 32
        - 64
        - 128
      batch_sizes:
        - 4
        - 8
        - 16
        - 32
        - 64
        - 128
        - 1024
        - 2048
      split_ratio: 0.8_0.9
      filters:
        - 1
        - 2
        - 3
        - 4
      l1:
        - 0.01
        - 0.02
        - 0.03
        - 0.04
        - 0.05
        - 0.001
        - 0.001
        - 0.001
        - 0.001
        - 0.001
        - 0.0001
        - 0.0002
        - 0.0003
        - 0.0004
        - 0.0005
        - 0.1
        - 0.2
      l2:
        - 0.01
        - 0.02
        - 0.03
        - 0.04
        - 0.05
        - 0.001
        - 0.001
        - 0.001
        - 0.001
        - 0.001
        - 0.0001
        - 0.0002
        - 0.0003
        - 0.0004
        - 0.0005
        - 0.1
        - 0.2
      lr:
        - 0.01
        - 0.02
        - 0.03
        - 0.04
        - 0.05
        - 0.001
        - 0.001
        - 0.001
        - 0.001
        - 0.001
        - 0.0001
        - 0.0002
        - 0.0003
        - 0.0004
        - 0.0005
        - 0.1
        - 0.2
      kernel_size:
        - 1
        - 2
        - 3
        - 4
      max_pooling_unit:
        - 1
        - 2
        - 3
        - 4
      lstm_units:
        - 4
        - 8
        - 16
        - 32
        - 64
        - 128
      units:
        - 4
        - 8
        - 16
        - 32
        - 64
        - 128
      loss:
        - mae
        - mse
      drop_out_ratio: 0.1*0.5
      num_layers:
        min: 1
        max: 3



